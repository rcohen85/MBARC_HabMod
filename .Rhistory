salinity_500m = salinity[,,28]
salinity_1000m = salinity[,,33]
library(stringr)
library(R.matlab)
infolder = 'E:/hycom/'
outfolder = file.path('E:','fsle','trunc') #kind of a nuisance to write it this way, but different types of computers use different file separators, so in the long run it might be good?
latrange = c(24,46)
lonrange = c(-63,-82)
timerange = c(as.Date('2016/02/1'),as.Date('2019/04/30'))
allfiles = list.files(infolder,pattern = "*.mat",full.names = TRUE)
lonrange = 360+lonrange
if (!dir.exists(outfolder)){
dir.create(outfolder,recursive = TRUE)
}
for (i in seq_along(allfiles)){
#open a given file as a data frame
matdata = data.frame(readMat(allfiles[i]))
# get file date from file
fileDate = matdata$X1.1$Date
# convert from matlab time to UTC
times = as.POSIXct((fileDate-719529)*86400,format='%Y-%m-%d',origin='1970-01-01',tz="UTC")
if (times>=timerange[1] & times<=timerange[2]){
#get lats
lats = matdata$X1.1$Latitude
#get lons
lons = matdata$X1.1$Longitude
# get depths
depths = matdata$X1.1$Depth
#get other variables
ssh = matdata$X1.1$ssh
water_u = matdata$X1.1$u
water_v = matdata$X1.1$v
temp = matdata$X1.1$temperature
salinity = matdata$X1.1$salinity
# create data frames for each depth
covarList = c("water_u","water_v","temp","salinity")
# pull only layers for our depths of interest
# water u
water_u_0m = water_u[,,1]
water_u_200m = water_u[,,23]
water_u_500m = water_u[,,28]
water_u_1000m = water_u[,,33]
# water v
water_v_0m = water_v[,,1]
water_v_200m = water_v[,,23]
water_v_500m = water_v[,,28]
water_v_1000m = water_v[,,33]
# temp
temp_0m = temp[,,1]
temp_200m = temp[,,23]
temp_500m = temp[,,28]
temp_1000m = temp[,,33]
# salinity
salinity_0m = salinty[,,1]
salinity_200m = salinity[,,23]
salinity_500m = salinity[,,28]
salinity_1000m = salinity[,,33]
#save stuff
#get just the name of the file
tempname = read.table(text = allfiles[i],sep = '/')
usename = tempname[4]
usename = str_remove(usename,"_\\d\\d\\d\\d\\d\\d\\d\\d.nc")
savename = file.path(outfolder,paste(usename,'.Rdata',sep=""))
# #save data frame as .csv
# # write.csv(ncframe,savename)
# save(lats,lons,theta_max,fsle_max,file=savename)
#
# print(paste('Done with file ',allfiles[i]))
}
else {
#if skipping file, say so
print(paste('Skipping file ',allfiles[i],', outside of time bounds.'))
}}
timerange = c(as.Date('2016/02/01'),as.Date('2019/04/30'))
for (i in seq_along(allfiles)){
#open a given file as a data frame
matdata = data.frame(readMat(allfiles[i]))
# get file date from file
fileDate = matdata$X1.1$Date
# convert from matlab time to UTC
times = as.POSIXct((fileDate-719529)*86400,format='%Y-%m-%d',origin='1970-01-01',tz="UTC")
if (times>=timerange[1] & times<=timerange[2]){
#get lats
lats = matdata$X1.1$Latitude
#get lons
lons = matdata$X1.1$Longitude
# get depths
depths = matdata$X1.1$Depth
#get other variables
ssh = matdata$X1.1$ssh
water_u = matdata$X1.1$u
water_v = matdata$X1.1$v
temp = matdata$X1.1$temperature
salinity = matdata$X1.1$salinity
# create data frames for each depth
covarList = c("water_u","water_v","temp","salinity")
# pull only layers for our depths of interest
# water u
water_u_0m = water_u[,,1]
water_u_200m = water_u[,,23]
water_u_500m = water_u[,,28]
water_u_1000m = water_u[,,33]
# water v
water_v_0m = water_v[,,1]
water_v_200m = water_v[,,23]
water_v_500m = water_v[,,28]
water_v_1000m = water_v[,,33]
# temp
temp_0m = temp[,,1]
temp_200m = temp[,,23]
temp_500m = temp[,,28]
temp_1000m = temp[,,33]
# salinity
salinity_0m = salinty[,,1]
salinity_200m = salinity[,,23]
salinity_500m = salinity[,,28]
salinity_1000m = salinity[,,33]
#save stuff
#get just the name of the file
tempname = read.table(text = allfiles[i],sep = '/')
usename = tempname[4]
usename = str_remove(usename,"_\\d\\d\\d\\d\\d\\d\\d\\d.nc")
savename = file.path(outfolder,paste(usename,'.Rdata',sep=""))
# #save data frame as .csv
# # write.csv(ncframe,savename)
# save(lats,lons,theta_max,fsle_max,file=savename)
#
# print(paste('Done with file ',allfiles[i]))
}
else {
#if skipping file, say so
print(paste('Skipping file ',allfiles[i],', outside of time bounds.'))
}}
for (i in seq_along(allfiles)){
for (i in seq_along(allfiles)){
#open a given file as a data frame
matdata = data.frame(readMat(allfiles[i]))
# get file date from file
fileDate = matdata$X1.1$Date
# convert from matlab time to UTC
times = as.POSIXct((fileDate-719529)*86400,format='%Y-%m-%d',origin='1970-01-01',tz="UTC")
#if (times>=timerange[1] & times<=timerange[2]){
#get lats
lats = matdata$X1.1$Latitude
#get lons
lons = matdata$X1.1$Longitude
# get depths
depths = matdata$X1.1$Depth
#get other variables
ssh = matdata$X1.1$ssh
water_u = matdata$X1.1$u
water_v = matdata$X1.1$v
temp = matdata$X1.1$temperature
salinity = matdata$X1.1$salinity
# create data frames for each depth
covarList = c("water_u","water_v","temp","salinity")
# pull only layers for our depths of interest
# water u
water_u_0m = water_u[,,1]
water_u_200m = water_u[,,23]
water_u_500m = water_u[,,28]
water_u_1000m = water_u[,,33]
# water v
water_v_0m = water_v[,,1]
water_v_200m = water_v[,,23]
water_v_500m = water_v[,,28]
water_v_1000m = water_v[,,33]
# temp
temp_0m = temp[,,1]
temp_200m = temp[,,23]
temp_500m = temp[,,28]
temp_1000m = temp[,,33]
# salinity
salinity_0m = salinty[,,1]
salinity_200m = salinity[,,23]
salinity_500m = salinity[,,28]
salinity_1000m = salinity[,,33]
#save stuff
#get just the name of the file
tempname = read.table(text = allfiles[i],sep = '/')
usename = tempname[4]
usename = str_remove(usename,"_\\d\\d\\d\\d\\d\\d\\d\\d.nc")
savename = file.path(outfolder,paste(usename,'.Rdata',sep=""))
# #save data frame as .csv
# # write.csv(ncframe,savename)
# save(lats,lons,theta_max,fsle_max,file=savename)
#
# print(paste('Done with file ',allfiles[i]))
}
#open a given file as a data frame
matdata = data.frame(readMat(allfiles[i]))
i=1
infolder = 'E:/hycom/'
outfolder = file.path('E:','fsle','trunc') #kind of a nuisance to write it this way, but different types of computers use different file separators, so in the long run it might be good?
latrange = c(24,46)
lonrange = c(-63,-82)
allfiles = list.files(infolder,pattern = "*.mat",full.names = TRUE)
infolder = 'E:/hycom/'
source("~/GitHub/MBARC_HabMod/extract_FSLE_from_NCfiles.R", echo=TRUE)
library(ncdf4)
myFile = nc_open("E:/ModelingCovarData/Chl20160201")
myFile = load("E:/ModelingCovarData/Chl20160201")
myFile = load("E:/ModelingCovarData/Chl20160201.nc")
myFile = nc_open("E:/ModelingCovarData/Chl20160201")
myFile = load("E:/ModelingCovarData/Chl20160201.nc")
myFile = nc_open("E:/ModelingCovarData/Chl20160201.nc")
myData = data.frame(myFile)
ncvar_get(myFile)
View(myFile)
chl = myFile$var$chlor_a
View(chl)
lat = myFile$dim$latitude$vals
lon = myFile$dim$longitude$vals
View(myFile)
View(myFile)
View(myFile)
chl = myFile$var$chlor_a
lats = ncvar_get(myFile, "lat")
lats = ncvar_get(myFile, "latitude")
chl = ncvar_get(myFile, "chlor_a")
View(chl)
library(stringr)
library(lubridate)
library(ncdf4)
inDir = c("E:/ModelingCovarData/Chl") # directory containing .nc files
sites = c('HZ','OC','NC','BC','WC','NFC','HAT','GS','BP','BS','JAX')
# Only change these if using different sites
HAT_change = as_date('2017-05-01') # account for change in HAT location from site A to B
HARPs = t(data.frame(c(41.06165, -66.35155), # WAT_HZ
c(40.22999, -67.97798),  # WAT_OC
c(39.83295, -69.98194),  # WAT_NC
c(39.19192, -72.22735),  # WAT_BC
c(38.37337, -73.36985),  # WAT_WC
c(37.16452, -74.46585),  # NFC
c(35.30183,-74.8789,35.5841,-74.7499),  # HAT_A & HAT_B
c(33.66992, -75.9977),   # WAT_GS
c(32.10527, -77.09067),  # WAT_BP
c(30.58295, -77.39002),  # WAT_BS
c(30.27818, -80.22085)))  # JAX_D
rownames(HARPs) = sites
colnames(HARPs) = c("Lat1", "Lon1", "Lat2", "Lon2")
fileList = list.files(inDir,pattern = "*.nc",full.names = TRUE,recursive=TRUE)
# initialize arrays to hold data from all files matching sites
masterData.Chl = double()
masterData.Lat = double()
masterData.Lon = double()
masterData.Time = double()
for (i in seq_along(fileList)){
# Open a given .nc file
ncdata = nc_open(fileList[i])
# get 6-digit datestamps from file names
fileDate = str_extract(fileList[i],"\\d\\d\\d\\d\\d\\d\\d\\d")
time_temp = paste(str_sub(fileDate,start=1L,end=4L),'-',
str_sub(fileDate,start=5L,end=6L),'-',
str_sub(fileDate,start=7L,end=8L),sep="")
thisFileTime = as.Date(time_temp,format='%Y-%m-%d',tz="UTC")
# get latitude values from file
lats = ncvar_get(ncdata,"latitude")
# get longitude values from file
lons = ncvar_get(ncdata, "longitude")
# get chlorophyll values from file
chl = ncvar_get(ncdata, "chlor_a")
# # initialize arrays to hold relevant data points from this file
# thisFile.Fsle = double()
# thisFile.Lat = double()
# thisFile.Lon = double()
# thisFile.Time = double()
#for each file in fileList
thisFileChl = matrix(nrow=11,ncol=1)
thisFileLat = matrix(nrow=11,ncol=1)
thisFileLon = matrix(nrow=11,ncol=1)
for (m in 1:nrow(HARPs)){ # for each HARP site
# find data points nearest this HARP site
if (m==7){ # at HAT, pull points first from site A, then from site B
if (thisFileTime<HAT_change){
sitelat = which.min(abs(HARPs[m,1]-lats))
sitelon = which.min(abs(HARPs[m,2]-lons))
} else {
sitelat = which.min(abs(HARPs[m,3]-lats))
sitelon = which.min(abs(HARPs[m,4]-lons))
}
} else {
sitelat = which.min(abs(HARPs[m,1]-lats))
sitelon = which.min(abs(HARPs[m,2]-lons))
}
# grab fsle values at this HARP site
thisFileChl[m,1] = chl[sitelon,sitelat]
thisFileLat[m] = lats[sitelat]
thisFileLon[m] = lons[sitelon]
}
# # add data from each HARP site to array for this file
# thisFile.Fsle = cbind(thisFile.Fsle,fsle)
# thisFile.Lat = cbind(thisFile.Lat,thisFsleLat)
# thisFile.Lon = cbind(thisFile.Lon,thisFsleLon)
# thisFile.Time = times
# add data points from all files to master data frame
masterData.Chl = cbind(masterData.Chl, thisFileChl)
masterData.Lat = cbind(masterData.Lat,thisFileLat)
masterData.Lon = cbind(masterData.Lon,thisFileLon)
masterData.Time = cbind(masterData.Time,thisFileTime)
}
View(masterData.Chl)
View(masterData.Lat)
View(masterData.Lon)
View(masterData.Time)
View(chl)
which(!is.na(chl))
clean = which(!is.na(chl))
72807/241753
*100
0.3011628*100
save(masterData.Chl,masterData.Lat,masterData.Lon,masterData.Time,
file=paste(inDir,'/','Chl_TS.Rdata',sep=""))
source("~/GitHub/MBARC_HabMod/make_TS_from_ERDDAP_nc.R", echo=TRUE)
source("~/GitHub/MBARC_HabMod/make_TS_from_ERDDAP_nc.R", echo=TRUE)
source("~/GitHub/MBARC_HabMod/make_TS_from_ERDDAP_nc.R", echo=TRUE)
paste(inDir,'/','Chl_',fileDate,'.Rdata',sep="")
source("~/GitHub/MBARC_HabMod/make_TS_from_ERDDAP_nc.R", echo=TRUE)
library(stringr)
library(lubridate)
library(ncdf4)
inDir = c("E:/ModelingCovarData/Chl") # directory containing .nc files
sites = c('HZ','OC','NC','BC','WC','NFC','HAT','GS','BP','BS','JAX')
# Only change these if using different sites
HAT_change = as_date('2017-05-01') # account for change in HAT location from site A to B
HARPs = t(data.frame(c(41.06165, -66.35155), # WAT_HZ
c(40.22999, -67.97798),  # WAT_OC
c(39.83295, -69.98194),  # WAT_NC
c(39.19192, -72.22735),  # WAT_BC
c(38.37337, -73.36985),  # WAT_WC
c(37.16452, -74.46585),  # NFC
c(35.30183,-74.8789,35.5841,-74.7499),  # HAT_A & HAT_B
c(33.66992, -75.9977),   # WAT_GS
c(32.10527, -77.09067),  # WAT_BP
c(30.58295, -77.39002),  # WAT_BS
c(30.27818, -80.22085)))  # JAX_D
rownames(HARPs) = sites
colnames(HARPs) = c("Lat1", "Lon1", "Lat2", "Lon2")
fileList = list.files(inDir,pattern = "*.nc",full.names = TRUE,recursive=TRUE)
# initialize arrays to hold data from all files matching sites
masterData.Data = double()
masterData.Lat = double()
masterData.Lon = double()
masterData.Time = double()
for (i in seq_along(fileList)){
# Open a given .nc file
ncdata = nc_open(fileList[i])
# get 6-digit datestamps from file names
fileDate = str_extract(fileList[i],"\\d\\d\\d\\d\\d\\d\\d\\d")
time_temp = paste(str_sub(fileDate,start=1L,end=4L),'-',
str_sub(fileDate,start=5L,end=6L),'-',
str_sub(fileDate,start=7L,end=8L),sep="")
thisFileTime = as.Date(time_temp,format='%Y-%m-%d',tz="UTC")
# get latitude values from file
lats = ncvar_get(ncdata,"latitude")
# get longitude values from file
lons = ncvar_get(ncdata, "longitude")
# get chlorophyll values from file
data = ncvar_get(ncdata, "chlor_a")
# save these values for each file
save(lats,lons,data,file=paste(inDir,'/','Chl_',fileDate,'.Rdata',sep=""))
# # initialize arrays to hold relevant data points from this file
# thisFile.Fsle = double()
# thisFile.Lat = double()
# thisFile.Lon = double()
# thisFile.Time = double()
#for each file in fileList
thisFileData = matrix(nrow=11,ncol=1)
thisFileLat = matrix(nrow=11,ncol=1)
thisFileLon = matrix(nrow=11,ncol=1)
for (m in 1:nrow(HARPs)){ # for each HARP site
# find data points nearest this HARP site
if (m==7){ # at HAT, pull points first from site A, then from site B
if (thisFileTime<HAT_change){
sitelat = which.min(abs(HARPs[m,1]-lats))
sitelon = which.min(abs(HARPs[m,2]-lons))
} else {
sitelat = which.min(abs(HARPs[m,3]-lats))
sitelon = which.min(abs(HARPs[m,4]-lons))
}
} else {
sitelat = which.min(abs(HARPs[m,1]-lats))
sitelon = which.min(abs(HARPs[m,2]-lons))
}
# grab fsle values at this HARP site
thisFileData[m,1] = data[sitelon,sitelat]
thisFileLat[m] = lats[sitelat]
thisFileLon[m] = lons[sitelon]
}
# # add data from each HARP site to array for this file
# thisFile.Fsle = cbind(thisFile.Fsle,fsle)
# thisFile.Lat = cbind(thisFile.Lat,thisFsleLat)
# thisFile.Lon = cbind(thisFile.Lon,thisFsleLon)
# thisFile.Time = times
# add data points from all files to master data frame
masterData.Data = cbind(masterData.Data, thisFileData)
masterData.Lat = cbind(masterData.Lat,thisFileLat)
masterData.Lon = cbind(masterData.Lon,thisFileLon)
masterData.Time = cbind(masterData.Time,thisFileTime)
}
for (i in seq_along(fileList)){
# Open a given .nc file
ncdata = nc_open(fileList[i])
# get 6-digit datestamps from file names
fileDate = str_extract(fileList[i],"\\d\\d\\d\\d\\d\\d\\d\\d")
time_temp = paste(str_sub(fileDate,start=1L,end=4L),'-',
str_sub(fileDate,start=5L,end=6L),'-',
str_sub(fileDate,start=7L,end=8L),sep="")
thisFileTime = as.Date(time_temp,format='%Y-%m-%d',tz="UTC")
# get latitude values from file
lats = ncvar_get(ncdata,"latitude")
# get longitude values from file
lons = ncvar_get(ncdata, "longitude")
# get chlorophyll values from file
data = ncvar_get(ncdata, "chlor_a")
# save these values for each file
save(lats,lons,data,file=paste(inDir,'/','Chl_',fileDate,'.Rdata',sep=""))
# # initialize arrays to hold relevant data points from this file
# thisFile.Fsle = double()
# thisFile.Lat = double()
# thisFile.Lon = double()
# thisFile.Time = double()
#for each file in fileList
thisFileData = matrix(nrow=11,ncol=1)
thisFileLat = matrix(nrow=11,ncol=1)
thisFileLon = matrix(nrow=11,ncol=1)
for (m in 1:nrow(HARPs)){ # for each HARP site
# find data points nearest this HARP site
if (m==7){ # at HAT, pull points first from site A, then from site B
if (thisFileTime<HAT_change){
sitelat = which.min(abs(HARPs[m,1]-lats))
sitelon = which.min(abs(HARPs[m,2]-lons))
} else {
sitelat = which.min(abs(HARPs[m,3]-lats))
sitelon = which.min(abs(HARPs[m,4]-lons))
}
} else {
sitelat = which.min(abs(HARPs[m,1]-lats))
sitelon = which.min(abs(HARPs[m,2]-lons))
}
# grab fsle values at this HARP site
thisFileData[m,1] = data[sitelon,sitelat]
thisFileLat[m] = lats[sitelat]
thisFileLon[m] = lons[sitelon]
}
# # add data from each HARP site to array for this file
# thisFile.Fsle = cbind(thisFile.Fsle,fsle)
# thisFile.Lat = cbind(thisFile.Lat,thisFsleLat)
# thisFile.Lon = cbind(thisFile.Lon,thisFsleLon)
# thisFile.Time = times
# add data points from all files to master data frame
masterData.Data = cbind(masterData.Data, thisFileData)
masterData.Lat = cbind(masterData.Lat,thisFileLat)
masterData.Lon = cbind(masterData.Lon,thisFileLon)
masterData.Time = cbind(masterData.Time,thisFileTime)
}
i=1
# Open a given .nc file
ncdata = nc_open(fileList[i])
source("~/GitHub/MBARC_HabMod/make_TS_from_ERDDAP_nc.R", echo=TRUE)
source("~/GitHub/MBARC_HabMod/make_TS_from_ERDDAP_nc.R", echo=TRUE)
source("~/GitHub/MBARC_HabMod/make_TS_from_ERDDAP_nc.R", echo=TRUE)
source("~/GitHub/MBARC_HabMod/make_TS_from_ERDDAP_nc.R", echo=TRUE)
source("~/GitHub/MBARC_HabMod/make_TS_from_ERDDAP_nc.R", echo=TRUE)
shiny::runApp('E:/CovarShinyApp')
runApp('E:/CovarShinyApp')
runApp('E:/CovarShinyApp')
runApp('E:/CovarShinyApp')
runApp('E:/CovarShinyApp')
runApp('E:/CovarShinyApp')
setwd("~/GitHub/MBARC_HabMod")
debugSource("~/GitHub/MBARC_HabMod/make_TS_from_ERDDAP_nc.R", echo=TRUE)
debugSource("~/GitHub/MBARC_HabMod/make_TS_from_ERDDAP_nc.R", echo=TRUE)
which.min(abs(HARPs[m,2]-lons))
which.min(abs(HARPs[m,2]-lons))
which.min(abs(HARPs[m,2]-lons))
source("~/GitHub/MBARC_HabMod/make_TS_from_ERDDAP_nc.R", echo=TRUE)
load('E:/ModelingCovarData/Chl/Chl_TS.Rdata')
goodPoints = which(!is.na(masterData.Data[1,]))
goodPoints = which(!is.na(masterData.Data[2,]))
goodPoints = which(!is.na(masterData.Data[3,]))
goodPoints = which(!is.na(masterData.Data[4,]))
goodPoints = which(!is.na(masterData.Data[5,]))
goodPoints = which(!is.na(masterData.Data[6,]))
goodPoints = which(!is.na(masterData.Data[7,]))
goodPoints = which(!is.na(masterData.Data[8,]))
goodPoints = which(!is.na(masterData.Data[9,]))
goodPoints = which(!is.na(masterData.Data[10,]))
goodPoints = which(!is.na(masterData.Data[11,]))
plot(masterData.Chl[1,],type="p",main="HZ")
plot(masterData.Chl[2,],type="p",main="OC")
plot(masterData.Chl[3,],type="p",main="NC")
plot(masterData.Chl[4,],type="p",main="BC")
plot(masterData.Chl[5,],type="p",main="WC")
plot(masterData.Chl[6,],type="p",main="NFC")
plot(masterData.Chl[7,],type="p",main="HAT")
plot(masterData.Chl[8,],type="p",main="GS")
plot(masterData.Chl[9,],type="p",main="BP")
plot(masterData.Chl[10,],type="p",main="BS")
plot(masterData.Chl[11,],type="p",main="JAX")
plot(masterData.Data[1,],type="p",main="HZ")
plot(masterData.Data[2,],type="p",main="OC")
plot(masterData.Data[3,],type="p",main="NC")
plot(masterData.Data[4,],type="p",main="BC")
plot(masterData.Data[5,],type="p",main="WC")
plot(masterData.Data[6,],type="p",main="NFC")
plot(masterData.Data[7,],type="p",main="HAT")
plot(masterData.Data[8,],type="p",main="GS")
plot(masterData.Data[9,],type="p",main="BP")
plot(masterData.Data[10,],type="p",main="BS")
plot(masterData.Data[11,],type="p",main="JAX")
source("~/GitHub/MBARC_HabMod/make_TS_from_ERDDAP_nc.R", echo=TRUE)
