#--------------------------------------------
#install.packages('swfscMisc')
library('swfscMisc')
#install.packages('dplyr')
library(dplyr)
#install.packages('geosphere')
library('geosphere')
# Specify the year you want to analyze
year = '2016'
# Specify the month you want to analyze
month = '01'
# Specify the zone you want to analyze with TWO digits (example: 01, 12)
zone = '19'
# Specify the latitude and longitude of your site in decimal degrees
site = c(41.0618333, -66.35158)
# Specify the radius you would like to filter in
radius = 10
#Specify Directory of MBARC_MarineCadastre (include backslash at end)
dir = 'G:/Shared Drives/MBARC_MarineCadastre/'
# Setting up directory with year to be analyzed
data_dir = paste(dir,year, sep = "")
# Pulling all .csv files from zone and month of interest (THIS WILL TAKE SOME TIME)
filePaths <- list.files(data_dir,
pattern  = paste(month, '_Zone', zone, '.csv', sep = ""),
all.files = TRUE,
recursive = TRUE,
full.names = TRUE)
# Reading csv file (THIS WILL TAKE SOME TIME)
df = data.frame(lapply(filePaths, read.csv))
View(df)
View(df)
View(df)
circleSite = data.frame(circle.polygon(site[1], site[2], radius))
View(circleSite)
colnames(circleSite) = c("Lat", "Lon")
View(circleSite)
circleSite$Lon = as.numeric(circleSite$Lon)
circleSite$Lat = as.numeric(circleSite$Lat)
n<-dim(circleSite)[1]
circleSite = circleSite[1:(n-1), ]
dfCoord = cbind("longitude" = df$LON,
"latitude"= df$LAT)
df = data.frame(df,
within_Rad = geosphere::distHaversine(
dfCoord,
c(site[2], site[1])
) / 1000 < radius)    # convert m to km, check < 5
View(df)
dfRad = filter(df, within_Rad == "TRUE")
dfRad$DayDate = as.POSIXct(dfRad$BaseDateTime)
uVesselDay = distinct(dfRad, MMSI, DayDate, .keep_all = TRUE)
uVesselDay$shipTypeDetail = NA
uVesselDay$shipTypeDetail = with(uVesselDay,
ifelse(VesselType == 0, "Other",
ifelse(VesselType == 30, "Fishing",
ifelse(VesselType >30 & VesselType < 33, "Tug",
ifelse(VesselType == 35, "Military",
ifelse(VesselType > 35 & VesselType < 38, "Pleasure",
ifelse(VesselType == 52, "Tug",
ifelse(VesselType > 59 & VesselType < 70, "Passenger",
ifelse(VesselType > 69 & VesselType < 80, "Cargo",
ifelse(VesselType > 79 & VesselType < 90, "Tanker",
ifelse(VesselType >1000 & VesselType < 1003, "Fishing",
ifelse(VesselType > 1002 & VesselType < 1005, "Cargo",
ifelse(VesselType > 1011 & VesselType < 1016, "Passenger",
ifelse(VesselType == 1016, "Cargo",
ifelse(VesselType == 1017, "Tanker",
ifelse(VesselType == 1019, "Pleasure",
ifelse(VesselType == 1021, "Military",
ifelse(VesselType == 1023, "Tug",
ifelse(VesselType == 1024, "Tanker",
ifelse(VesselType == 1025, "Tug",
ifelse(is.na(VesselType), "Other",
ifelse(VesselType == 1022, "Other", "Other"))))))))))))))))))))))
uVesselDay$shipTypeDetail[is.na(uVesselDay$shipTypeDetail)] = "Other"
View(uVesselDay)
uVesselDay = distinct(dfRad, MMSI, DayDate, .keep_all = TRUE)
View(uVesselDay)
View(dfCoord)
View(uVesselDay)
View(dfRad)
df = data.frame(df,
within_Rad = geosphere::distHaversine(
dfCoord,
c(site[2], site[1])
) / 1000 < radius)    # convert m to km, check < 5
dfRad = filter(df, within_Rad == "TRUE")
dfRad$DayDate = as.POSIXct(dfRad$BaseDateTime)
uVesselDay = distinct(dfRad, MMSI, DayDate, .keep_all = TRUE)
uVesselDay$shipTypeDetail = NA
dfRad$DayDate = as.POSIXct(dfRad$BaseDateTime)
uVesselDay$shipTypeDetail = with(uVesselDay,
ifelse(VesselType == 0, "Other",
ifelse(VesselType == 30, "Fishing",
ifelse(VesselType >30 & VesselType < 33, "Tug",
ifelse(VesselType == 35, "Military",
ifelse(VesselType > 35 & VesselType < 38, "Pleasure",
ifelse(VesselType == 52, "Tug",
ifelse(VesselType > 59 & VesselType < 70, "Passenger",
ifelse(VesselType > 69 & VesselType < 80, "Cargo",
ifelse(VesselType > 79 & VesselType < 90, "Tanker",
ifelse(VesselType >1000 & VesselType < 1003, "Fishing",
ifelse(VesselType > 1002 & VesselType < 1005, "Cargo",
ifelse(VesselType > 1011 & VesselType < 1016, "Passenger",
ifelse(VesselType == 1016, "Cargo",
ifelse(VesselType == 1017, "Tanker",
ifelse(VesselType == 1019, "Pleasure",
ifelse(VesselType == 1021, "Military",
ifelse(VesselType == 1023, "Tug",
ifelse(VesselType == 1024, "Tanker",
ifelse(VesselType == 1025, "Tug",
ifelse(is.na(VesselType), "Other",
ifelse(VesselType == 1022, "Other", "Other"))))))))))))))))))))))
uVesselDay$shipTypeDetail[is.na(uVesselDay$shipTypeDetail)] = "Other"
dailyshipCount_Type = uVesselDay %>% count(DayDate, shipTypeDetail)
View(dailyshipCount_Type)
plot2 = ggplot(dailyshipCount_Type, aes(x = DayDate, y = n, fill = shipTypeDetail))+
geom_col(position = position_dodge2(width = 0.9, preserve = "single"), size = 5)+
xlab('Date')+
ylab('Count')+
guides(fill=guide_legend(title="Ship Type"))
library(ggplot2)
plot2 = ggplot(dailyshipCount_Type, aes(x = DayDate, y = n, fill = shipTypeDetail))+
geom_col(position = position_dodge2(width = 0.9, preserve = "single"), size = 5)+
xlab('Date')+
ylab('Count')+
guides(fill=guide_legend(title="Ship Type"))
plot2
# Enter covariate(s) of interest
covars = c("salinity","water_temp")
# Enter regions of interest; "global" (1/12degree) OR "GoM" (1/25degree)
region <- c("global")
# Enter date range(s) of interest in pairs of start/end dates
dateS <- as.Date(c('2016-05-01')) # start date(s)
dateE <- as.Date(c('2016-07-30')) # end date(s)
# Enter study area boundaries in decimal degree lat/long limits
latS <- c(24) # southern bound(s)
latN <- c(46) # northern bound(s)
lonE <- c(-63) # eastern bound(s); use "-" for west of Prime Meridian
lonW <- c(-82) # western bound(s); use "-" for west of Prime Meridian
# SET AT LEAST ONE OF THESE TO NaN
vertCoord = 1 # Enter a single vertical layer to grab (e.g. 1 for 0.0m, see depths above) OR
vertStride = NaN # Enter vertical stride (1 for all depth layers, 2 for every other, etc.)
# Directory to save data; be sure to use forward slashes!
saveDir = "J:/DataScrapingCode/Test"
library(pracma)
library(curl)
# Check if save directory exists; if not, then create it
dir.create(file.path(saveDir), recursive = TRUE, showWarnings = FALSE)
setwd(saveDir)
# Base urls and data dates for each experiment; note these dates do not reflect the true start/end
# dates of the experiments, but are adjusted to eradicate temporal overlap between experiments
global_expts = data.frame(
url=c('http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/1994',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/1995',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/1996',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/1997',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/1998',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/1999',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2000',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2001',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2002',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2003',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2004',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2005',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2006',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2007',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2008',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2009',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2010',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2011',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2012',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2013',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2014',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_56.3',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_57.2',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_92.8',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_57.7',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_92.9',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_93.0',
'http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_93.0'),
start=c(as.Date('1994-01-01'), as.Date('1995-01-01'), as.Date('1996-01-01'),
as.Date('1997-01-01'), as.Date('1998-01-01'), as.Date('1999-01-01'),
as.Date('2000-01-01'), as.Date('2001-01-01'), as.Date('2002-01-01'),
as.Date('2003-01-01'), as.Date('2004-01-01'), as.Date('2005-01-01'),
as.Date('2006-01-01'), as.Date('2007-01-01'), as.Date('2008-01-01'),
as.Date('2009-01-01'), as.Date('2010-01-01'), as.Date('2011-01-01'),
as.Date('2012-01-01'), as.Date('2013-01-01'), as.Date('2014-01-01'),
as.Date('2014-07-01'), as.Date('2016-10-01'), as.Date('2017-02-01'),
as.Date('2017-06-01'), as.Date('2017-10-01'), as.Date('2018-01-01'),
as.Date('2020-02-19')),
end=c(as.Date('1994-12-31'), as.Date('1995-12-31'), as.Date('1996-12-31'),
as.Date('1997-12-31'), as.Date('1998-12-31'), as.Date('1999-12-31'),
as.Date('2000-12-31'), as.Date('2001-12-31'), as.Date('2002-12-31'),
as.Date('2003-12-31'), as.Date('2004-12-31'), as.Date('2005-12-31'),
as.Date('2006-12-31'), as.Date('2007-12-31'), as.Date('2008-12-31'),
as.Date('2009-12-31'), as.Date('2010-12-31'), as.Date('2011-12-31'),
as.Date('2012-12-31'), as.Date('2013-12-31'), as.Date('2014-06-30'),
as.Date('2016-09-30'), as.Date('2017-01-31'), as.Date('2017-05-31'),
as.Date('2017-09-30'), as.Date('2017-12-31'), as.Date('2020-02-18'),
Sys.Date() - 2))
gom_expts = data.frame(
url=c('http://ncss.hycom.org/thredds/ncss/GOMu0.04/expt_50.1',
'http://ncss.hycom.org/thredds/ncss/GOMl0.04/expt_31.0',
'http://ncss.hycom.org/thredds/ncss/GOMl0.04/expt_32.5',
'http://ncss.hycom.org/thredds/ncss/GOMu0.04/expt_90.1m000'),
start=c(as.Date('1993-01-01'), as.Date('2013-01-01'), as.Date('2014-09-01'), as.Date('2019-01-01')),
end=c(as.Date('2012-12-31'), as.Date('2014-08-30'), as.Date('2018-12-31'), as.Date('2021-07-15')))
i=1
k=1
l=1
q <- which(dateS[i] >= global_expts$start)
r <- which(dateE[i] <= global_expts$end)
idxRange <- c(tail(q,1):r[1])
url <- global_expts$url[idxRange]
dateSubsetStarts <- global_expts$start[idxRange] # subset date ranges by experiment
dateSubsetEnds <- global_expts$end[idxRange]
dateSubsetStarts[1] <- dateS[i]
dateSubsetEnds[length(dateSubsetEnds)] <- dateE[i]
dlSpecs <- '?'
# Add the variable
dlSpecs = sprintf('%svar=%s&', dlSpecs, covars[l])
# Add the spatial bounds
dlSpecs = sprintf('%snorth=%.4f&west=%.4f&east=%.4f&south=%.4f&disableProjSubset=on&horizStride=1&',
dlSpecs, latN[k], lonW[k], lonE[k], latS[k] )
# Specify vertical layers
if (!is.na(vertCoord)){
dlSpecs = sprintf('%svertCoord=%d&', dlSpecs, vertCoord)}
if (!is.na(vertStride)){
dlSpecs = sprintf('%svertStride=%d&', dlSpecs, vertStride)}
# Download associated lat-lon points
dlSpecs = sprintf('%saddLatLon=true&', dlSpecs)
# Get data in netcdf4 format
dlSpecs = sprintf('%saccept=netcdf4&', dlSpecs)
# Add the time range(s) and construct download url(s)
for (j in 1:length(url)){
url[j] <- paste(url[j],sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1',
dlSpecs, strftime(dateSubsetStarts[j], '%Y-%m-%dT00'),
strftime(dateSubsetEnds[j], '%Y-%m-%dT00')),sep='')}
url
inDir = 'I:\TimeSeries'
inDir = 'I:\TimeSeries'
inDir = 'I:/TimeSeries'
## Settings -------------------------------------------------------
inDir = c('E:/ModelingCovarData/Temperature')
covar = 'water_temp'
depths = c(0,50,100,200,500,1000,2000, 3000,4000) # order to organize depth layers for plotting
sites = c('HZ','OC','NC','BC','WC','NFC','HAT','GS','BP','BS','JAX')
HARPs = t(data.frame(c(41.06165, -66.35155), # WAT_HZ
c(40.22999, -67.97798),  # WAT_OC
c(39.83295, -69.98194),  # WAT_NC
c(39.19192, -72.22735),  # WAT_BC
c(38.37337, -73.36985),  # WAT_WC
c(37.16452, -74.46585),  # NFC
c(35.30183, -74.87895),  # HAT
c(33.66992, -75.9977),   # WAT_GS
c(32.10527, -77.09067),  # WAT_BP
c(30.58295, -77.39002),  # WAT_BS
c(30.27818, -80.22085)))  # JAX_D
rownames(HARPs) = sites
colnames(HARPs) = c("Lat","Lon")
# initialize data frames for each site
action = paste(sites,rep('=',length(sites)),rep('double()',
length(sites)),collapse=";")
eval(parse(text=action))
action = paste(paste(sites,rep('_time',length(sites)),sep=""),rep('=',length(sites)),
rep('double()',length(sites)),collapse=";")
eval(parse(text=action))
fileList = dir(inDir,".Rdata")
for (i in 1:length(fileList)){
# Load data from this depth
load(paste(inDir,'/',fileList[i],sep=""))
# Get depth level from file
thisFile = fileList[i]
thisDepth = str_replace(thisFile,paste(covar,'_',sep=""),"")
thisDepth = as.numeric(str_replace(thisDepth,"m.Rdata",""))
depthInd = which(depths==thisDepth)
# loop through HARP sites
for (j in 1:length(sites)){
# for each site, find observations which have Lat & Lon values closest to this site
sitelat = which.min(abs(HARPs[j,1]-masterData.Lat))
# sitelon = which.min(abs(HARPs[j,2]-masterData.Lon))
# Pull obs to the appropriate site's data frame, with depth given by row
action = paste(sites[j],' = rbind(',sites[j],',masterData.Covar[sitelat,])',sep="")
eval(parse(text=action))
action = paste(sites[j],'_time = rbind(',sites[j],'_time,masterData.Time[sitelat,])',sep="")
eval(parse(text=action))
}
#Temperature
# #create data frames, add depth column
# temp0m <- data.frame(sapply(water_temp_0m,c))
# temp0m$Depth <- c(0)
# temp50m <- data.frame(sapply(water_temp_50m,c))
# temp50m$Depth <- c(50)
# temp100m <- data.frame(sapply(water_temp_100m,c))
# temp100m$Depth <- c(100)
# temp200m <- data.frame(sapply(water_temp_200m,c))
# temp200m$Depth <- c(200)
# temp500m <- data.frame(sapply(water_temp_500m,c))
# temp500m$Depth <- c(500)
# temp1000m <- data.frame(sapply(water_temp_1000m,c))
# temp1000m$Depth <- c(1000)
# temp3000m <- data.frame(sapply(water_temp_3000m,c))
# temp3000m$Depth <- c(3000)
# temp4000m <- data.frame(sapply(water_temp_4000m,c))
# temp4000m$Depth <- c(4000)
#
# #create a list of data frames to be merged
# temp_list <- list(temp0m, temp50m, temp100m,
#                   temp200m, temp500m, temp1000m,
#                   temp3000m, temp4000m)
# #merge all data frames together
# tempAllDepths <- temp_list %>% reduce(full_join)
# tempAllDepths <- as.data.frame(tempAllDepths)
}
debugSource("~/GitHub/MBARC_HabMod/plot_HYCOM_data.R", echo=TRUE)
y= as.vector(t(HZ_time))
depthVar = rep(depths,each=dim(HZ)[2])
HZ_plot=as.data.frame(cbind(x,y,depthVar))
colnames(HZ_plot) = c("Data","Time","Depth")
ggplot(HZ_plot_clean, aes(x=Time, y=Depth, z=Data)) +
stat_contour() +
scale_y_reverse()
ggplot(HZ_plot, aes(x=Time, y=Depth, z=Data)) +
stat_contour() +
scale_y_reverse()
y= as.vector(t(HZ_time))
depthVar = rep(depths,each=dim(HZ)[2])
HZ_plot=as.data.frame(cbind(x,y,depthVar))
#CREATE CONTOUR PLOTS ---------------------------------------------------------------
x = unlist(lapply(HZ,c));y= unlist(lapply(HZ_time,c))
HZ_plot=as.data.frame(cbind(x,y))
HZ_plot=as.data.frame(cbind(HZ_plot,c(depths)))
colnames(HZ_plot) = c("Data","Time","Depth")
ggplot(HZ_plot, aes(x=Time, y=Depth, z=Data)) +
stat_contour() +
scale_y_reverse()
colnames(HZ_plot) = c("Data","Time","Depth")
#CREATE CONTOUR PLOTS ---------------------------------------------------------------
x = unlist(lapply(HZ,c));y= unlist(lapply(HZ_time,c))
HZ_plot=as.data.frame(cbind(x,y))
HZ_plot=as.data.frame(cbind(HZ_plot,c(depths)))
